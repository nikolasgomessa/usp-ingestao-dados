{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from abc import ABC, abstractmethod\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import glob\n",
    "import logging\n",
    "import boto3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rename = {\n",
    "    \"BanksTransformation\": {\n",
    "        \"Segmento\" : \"segmento\",\n",
    "        \"CNPJ\": \"cnpj\",\n",
    "        \"Nome\": \"nome\"\n",
    "    },\n",
    "    \"EmployeesTransformation\": {\n",
    "        \"employer-website\" : \"employer_website\",\n",
    "        \"employer-headquarters\": \"employer_headquarters\",\n",
    "        \"employer-founded\": \"employer_founded\",\n",
    "        \"employer-industry\": \"employer_industry\",\n",
    "        \"employer-revenue\": \"employer_revenue\",\n",
    "        \"Geral\": \"geral\",\n",
    "        \"Cultura e valores\": \"cultura_valores\",\n",
    "        \"Diversidade e inclus�o\": \"diversidade_inclusao\",\n",
    "        \"Qualidade de vida\": \"qualidade_vida\",\n",
    "        \"Alta lideran�a\": \"alta_lideranca\",\n",
    "        \"Remunera��o e benef�cios\": \"remuneracao_beneficios\",\n",
    "        \"Oportunidades de carreira\": \"oportunidades_carreira\",\n",
    "        \"Recomendam para outras pessoas(%)\": \"percentual_recomendam_para_outras_pessoas\",\n",
    "        \"Perspectiva positiva da empresa(%)\": \"percentual_perspectiva_positiva_empresa\",\n",
    "#         \"CNPJ\": \"cnpj\",\n",
    "        \"Nome\": \"nome\",\n",
    "        \"Segmento\": \"segmento\"\n",
    "    },\n",
    "    \"ComplaintsTransformation\": {\n",
    "        \"Ano\" : \"ano\",\n",
    "        \"Trimestre\": \"trimestre\",\n",
    "        \"Categoria\": \"categoria\",\n",
    "        \"Tipo\": \"tipo\",\n",
    "        \"CNPJ IF\": \"cnpj_if\",\n",
    "        \"Institui��o financeira\": \"instituicao_financeira\",\n",
    "        \"�ndice\": \"indice\",\n",
    "        \"Quantidade de reclama��es reguladas procedentes\": \"qtd_reclamacoes_reguladas_procedentes\",\n",
    "        \"Quantidade de reclama��es reguladas - outras\": \"qtd_reclamacoes_reguladas_outras\",\n",
    "        \"Quantidade de reclama��es n�o reguladas\": \"qtd_reclamacoes_nao_reguladas\",\n",
    "        \"Quantidade total de reclama��es\": \"qtd_total_reclamacoes\",\n",
    "        \"Quantidade total de clientes - CCS e SCR\": \"qtd_total_clientes_ccs_scr\",\n",
    "        \"Quantidade de clientes - CCS\": \"qtd_clientes_ccs\",\n",
    "        \"Quantidade de clientes - SCR\": \"qtd_clientes_scr\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedFileType(Exception):\n",
    "    def __init__(self, file_type):\n",
    "        self.file_type = file_type\n",
    "        self.message = f\"File(s) of type {file_type} not supported\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self, spark, file_directory: list, file_type: str, separator: str = ';', header: bool = True, encoding='utf-8'):\n",
    "        self.file_directory = file_directory\n",
    "        self.file_type = file_type\n",
    "        self.separator = separator\n",
    "        self.spark = spark\n",
    "        self.header = header\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def load(self) -> DataFrame:\n",
    "        if self.file_type in ('csv', 'tsv'):\n",
    "            return \\\n",
    "                self.spark.read.options(\n",
    "                    delimiter=self.separator,\n",
    "                    header=self.header,\n",
    "                    encoding=self.encoding\n",
    "                ).csv(self.file_directory)\n",
    "        else:\n",
    "            raise UnsupportedFileType(self.file_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing Name and DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformData(ABC):\n",
    "    \"\"\"\n",
    "    Gathers general functions for all transformations.\n",
    "    \"\"\"\n",
    "    def format_cnpj(self, value):\n",
    "        return F.when((value == ' ') | (value == ''), value).otherwise(F.lpad(value, 8, '0'))\n",
    "\n",
    "\n",
    "    def load_column_rename_mappings(self, transformation_name):\n",
    "#         json_file_path = os.path.join(os.path.dirname(__file__), 'column_rename.json')\n",
    "        column_rename_mappings = column_rename\n",
    "        return column_rename_mappings.get(transformation_name, {})\n",
    "\n",
    "\n",
    "    def rename_columns(self, df: DataFrame, column_rename) -> DataFrame:\n",
    "        for old_name, new_name in column_rename.items():\n",
    "            df = df.withColumnRenamed(old_name, new_name)\n",
    "        return df\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self) -> DataFrame:\n",
    "        pass\n",
    "\n",
    "\n",
    "class BanksTransformation(TransformData):\n",
    "    \"\"\"\n",
    "    Functions for transforming the pandas dataframe for banks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: DataFrame):\n",
    "        \"\"\"\n",
    "        Receives the dataframe.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.column_rename = self.load_column_rename_mappings('BanksTransformation')\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Function to rename (to snake_case), format, and adjust data in the 'Segment', 'CNPJ', and 'Name' columns.\n",
    "        Returns a dataframe.\n",
    "        \"\"\"\n",
    "        transformed_df = self.rename_columns(self.df, self.column_rename)\n",
    "        transformed_df = transformed_df.withColumn(\"cnpj\", self.format_cnpj(F.col(\"cnpj\")))\n",
    "        transformed_df = transformed_df.withColumn(\"nome\", F.regexp_replace(F.col(\"nome\").cast(StringType()), ' - PRUDENCIAL', ''))\n",
    "        return transformed_df\n",
    "\n",
    "\n",
    "class EmployeesTransformation(TransformData):\n",
    "    \"\"\"\n",
    "    Functions for transforming the pandas dataframe for employees.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: DataFrame):\n",
    "        \"\"\"\n",
    "        Receives the dataframe.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.column_rename = self.load_column_rename_mappings('EmployeesTransformation')\n",
    "\n",
    "\n",
    "    def transform(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Function to rename (to snake_case), format, and change data types.\n",
    "        Returns a dataframe.\n",
    "        \"\"\"\n",
    "        transformed_df = self.rename_columns(self.df, self.column_rename)\n",
    "\n",
    "        transformed_df = transformed_df\\\n",
    "            .withColumn(\"employer_name\", F.col('employer_name').cast(StringType()))\\\n",
    "            .withColumn(\"reviews_count\", F.col('reviews_count').cast(IntegerType()))\\\n",
    "            .withColumn(\"culture_count\", F.col('culture_count').cast(IntegerType()))\\\n",
    "            .withColumn(\"salaries_count\", F.col('salaries_count').cast(IntegerType()))\\\n",
    "            .withColumn(\"benefits_count\", F.col('benefits_count').cast(IntegerType()))\\\n",
    "            .withColumn(\"employer_website\", F.col('employer_website').cast(StringType()))\\\n",
    "            .withColumn(\"employer_headquarters\", F.col('employer_headquarters').cast(StringType()))\\\n",
    "            .withColumn(\"employer_founded\", F.col('employer_founded').cast(IntegerType()))\\\n",
    "            .withColumn(\"employer_industry\", F.col('employer_industry').cast(StringType()))\\\n",
    "            .withColumn(\"employer_revenue\", F.col('employer_revenue').cast(StringType()))\\\n",
    "            .withColumn(\"url\", F.col('url').cast(StringType()))\\\n",
    "            .withColumn(\"geral\", F.col('geral').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"cultura_valores\", F.col('cultura_valores').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"diversidade_inclusao\", F.col('diversidade_inclusao').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qualidade_vida\", F.col('qualidade_vida').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"alta_lideranca\", F.col('alta_lideranca').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"remuneracao_beneficios\", F.col('remuneracao_beneficios').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"oportunidades_carreira\", F.col('oportunidades_carreira').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"percentual_recomendam_para_outras_pessoas\", F.col('percentual_recomendam_para_outras_pessoas').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"percentual_perspectiva_positiva_empresa\", F.col('percentual_perspectiva_positiva_empresa').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"nome\", F.col('nome').cast(StringType()))\\\n",
    "            .withColumn(\"segmento\", F.col('segmento').cast(StringType()))\\\n",
    "            .withColumn(\"match_percent\", F.col('match_percent').cast(FloatType()))\n",
    "        #             .withColumn('cnpj', self.format_cnpj(F.col(\"cnpj\")))\\\n",
    "\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "\n",
    "    def calculate_aggregates(self, df) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Function to return a pandas dataframe of a pivot table grouped by the 'name' column,\n",
    "        aggregating the 'geral' and 'remuneracao_beneficios' columns by mean.\n",
    "        \"\"\"\n",
    "        aggregated_df  = df.groupby('nome').agg(\n",
    "            F.round(F.mean('geral'), 2).alias('geral'),\n",
    "            F.round(F.mean('remuneracao_beneficios'), 2).alias('remuneracao_beneficios')\n",
    "        )\n",
    "        return aggregated_df \n",
    "\n",
    "\n",
    "class ComplaintsTransformation(TransformData):\n",
    "    \"\"\"\n",
    "    Functions for transforming the pandas dataframe for complaints.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: DataFrame):\n",
    "        \"\"\"\n",
    "        Receives the dataframe.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.column_rename = self.load_column_rename_mappings('ComplaintsTransformation')\n",
    "\n",
    "\n",
    "    def transform(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Function to rename (to snake_case), format, and change data types.\n",
    "        Returns a dataframe.\n",
    "        \"\"\"\n",
    "        transformed_df = self.rename_columns(self.df, self.column_rename)\n",
    "\n",
    "        transformed_df = transformed_df\\\n",
    "            .withColumn(\"ano\", F.col('ano').cast(IntegerType()))\\\n",
    "            .withColumn('trimestre', F.col(\"trimestre\").cast(StringType()))\\\n",
    "            .withColumn('categoria', F.col(\"categoria\").cast(StringType()))\\\n",
    "            .withColumn('tipo', F.col(\"tipo\").cast(StringType()))\\\n",
    "            .withColumn(\"cnpj\", self.format_cnpj(F.col(\"cnpj_if\")))\\\n",
    "            .withColumn(\"nome\", F.regexp_replace(F.col(\"instituicao_financeira\").cast(StringType()), ' \\(conglomerado\\)', ''))\\\n",
    "            .withColumn(\"indice\", F.regexp_replace(F.col('indice').cast(StringType()), ',', '.').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_reclamacoes_reguladas_procedentes\", F.col('qtd_reclamacoes_reguladas_procedentes').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_reclamacoes_reguladas_outras\", F.col('qtd_reclamacoes_reguladas_outras').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_reclamacoes_nao_reguladas\", F.col('qtd_reclamacoes_nao_reguladas').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_total_reclamacoes\", F.col('qtd_total_reclamacoes').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_total_clientes_ccs_scr\", F.col('qtd_total_clientes_ccs_scr').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_clientes_ccs\", F.col('qtd_clientes_ccs').cast(DecimalType(20,2)))\\\n",
    "            .withColumn(\"qtd_clientes_scr\", F.col('qtd_clientes_scr').cast(DecimalType(20,2)))\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "\n",
    "    def calculate_aggregates(self, df) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Function to return a pandas dataframe of a pivot table grouped by the 'name' column,\n",
    "        aggregating columns like 'indice', 'qtd_total_reclamacoes', and 'qtd_total_clientes_ccs_scr' by mean.\n",
    "        \"\"\"\n",
    "        aggregated_df  = df.groupby('nome').agg(\n",
    "            F.round(F.mean('indice'), 2).alias(\"indice\"),\n",
    "            F.round(F.mean('qtd_total_reclamacoes'), 2).alias(\"qtd_total_reclamacoes\"),\n",
    "            F.max('qtd_total_clientes_ccs_scr').alias(\"qtd_total_clientes_ccs_scr\")\n",
    "        )\n",
    "        return aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "gc = GlueContext(self.sc.getOrCreate())\n",
    "spark = gc.spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_set_datatype() -> tuple:\n",
    "    \"\"\"\n",
    "    Initiates the main execution where a logger is initialized, the current directory is captured, and various tables are loaded,\n",
    "    transformed, concatenated into a single dataframe via join, and finally saved in a directory in the 'parquet' fixed format.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    load_banks = LoadData(\n",
    "        spark=spark,\n",
    "        file_directory='s3://bucket-boto-gabrafur-usp/raw_files/banco/', \n",
    "        file_type='tsv',\n",
    "        separator='\\t'\n",
    "    )\n",
    "    df_raw_banks = load_banks.load()\n",
    "\n",
    "    load_employees = LoadData(\n",
    "        spark=spark,\n",
    "        file_directory='s3://bucket-boto-gabrafur-usp/raw_files/empregados/', \n",
    "        file_type='csv',\n",
    "        separator='|'\n",
    "    )\n",
    "    df_raw_employees = load_employees.load()\n",
    "\n",
    "    load_complaints = LoadData(\n",
    "        spark=spark,\n",
    "        file_directory='s3://bucket-boto-gabrafur-usp/raw_files/reclamacoes/', \n",
    "        file_type='csv',\n",
    "        separator=';'\n",
    "    )\n",
    "    df_raw_complaints = load_complaints.load()\n",
    "\n",
    "    transform_banks = BanksTransformation(df_raw_banks)\n",
    "    df_banks = transform_banks.transform()\n",
    "\n",
    "    transform_employees = EmployeesTransformation(df_raw_employees)\n",
    "    df_employees = transform_employees.transform()\n",
    "\n",
    "    transform_complaints = ComplaintsTransformation(df_raw_complaints)\n",
    "    df_complaints = transform_complaints.transform()\n",
    "\n",
    "    return df_banks, df_employees, df_complaints\n",
    "\n",
    "df_banks, df_employees, df_complaints = read_and_set_datatype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWriter:\n",
    "    def write_parquet(self, df, output_directory, mode=\"overwrite\", repartition=True):\n",
    "        if repartition:\n",
    "            df.repartition(1).write.mode(mode).parquet(output_directory)\n",
    "        else:\n",
    "            df.write.mode(mode).parquet(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = DataWriter()\n",
    "\n",
    "output_directory = 's3://bucket-boto-gabrafur-usp/fixed/banco/'\n",
    "write_data.write_parquet(df_banks, output_directory)\n",
    "\n",
    "output_directory = 's3://bucket-boto-gabrafur-usp/fixed/empregados/'\n",
    "write_data.write_parquet(df_employees, output_directory)\n",
    "\n",
    "output_directory = 's3://bucket-boto-gabrafur-usp/fixed/reclamacoes/'\n",
    "write_data.write_parquet(df_complaints, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
