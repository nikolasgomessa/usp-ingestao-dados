{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recover spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_ge(output_path):\n",
    "  context = ge.get_context()\n",
    "\n",
    "  context.add_expectation_suite(\n",
    "      expectation_suite_name=suite_name\n",
    "  )\n",
    "\n",
    "  context.add_datasource(**yaml.load(datasource_yaml))\n",
    "  config_data_docs_site(context, output_path)\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def config_data_docs_site(context, output_path):\n",
    "    data_context_config = DataContextConfig()\n",
    "\n",
    "    data_context_config[\"data_docs_sites\"] = {\n",
    "        \"s3_site\": {\n",
    "            \"class_name\": \"SiteBuilder\",\n",
    "            \"store_backend\": {\n",
    "                \"class_name\": \"TupleS3StoreBackend\",\n",
    "                \"bucket\": output_path.replace(\"s3://\", \"\")\n",
    "            },\n",
    "            \"site_index_builder\": {\n",
    "                \"class_name\": \"DefaultSiteIndexBuilder\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    context._project_config[\"data_docs_sites\"] = data_context_config[\"data_docs_sites\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validator(context, suite, df):\n",
    "    runtime_batch_request = RuntimeBatchRequest(\n",
    "        datasource_name=\"my_spark_datasource\",\n",
    "        data_connector_name=\"my_runtime_data_connector\",\n",
    "        data_asset_name=\"insert_your_data_asset_name_here\",\n",
    "        runtime_parameters={\"batch_data\": df},\n",
    "        batch_identifiers={\n",
    "            \"some_key_maybe_pipeline_stage\": \"ingestion step 1\",\n",
    "            \"some_other_key_maybe_airflow_run_id\": \"run 18\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    df_validator: Validator = context.get_validator(\n",
    "        batch_request=runtime_batch_request,\n",
    "        expectation_suite=suite\n",
    "    )\n",
    "\n",
    "    return df_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_profile_suite(context, df_ge):\n",
    "    profiler = BasicDatasetProfiler()\n",
    "    expectation_suite, validation_result = profiler.profile(df_ge)\n",
    "    context.save_expectation_suite(expectation_suite, suite_profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tests_suite(df_validator):\n",
    "    columns_list = [\"product_id\", \"product_name\", \"category\", \"discounted_price\", \"actual_price\",\n",
    "                    \"discount_percentage\", \"rating\", \"rating_count\", \"about_product\", \"user_id\",\n",
    "                    \"user_name\", \"review_id\", \"review_title\", \"review_content\", \"img_link\", \"product_link\"]\n",
    "\n",
    "    df_validator.expect_table_columns_to_match_ordered_list(columns_list)\n",
    "    df_validator.expect_column_values_to_be_unique(\"product_id\")\n",
    "    df_validator.expect_column_values_to_not_be_null(\"product_id\")\n",
    "    df_validator.expect_column_values_to_be_between(column='discount_percentage', min_value=0, max_value=100)\n",
    "    df_validator.expect_column_values_to_be_between(column='rating', min_value=0, max_value=5)\n",
    "    df_validator.expect_column_values_to_match_regex(\n",
    "        column=\"product_link\",\n",
    "        regex=r'^https:\\/\\/www\\.[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,}$',\n",
    "        mostly=0.9\n",
    "    )\n",
    "    df_validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "    return df_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_emr = EmrCreateJobFlowOperator(\n",
    "    task_id='create_emr',\n",
    "    aws_conn_id='aws_default',\n",
    "    job_flow_overrides=JOB_FLOW_OVERRIDES,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "add_step = EmrAddStepsOperator(\n",
    "    task_id='add_step',\n",
    "    job_flow_id=\"{{ task_instance.xcom_pull(task_ids='create_emr', key='return_value') }}\",\n",
    "    steps=STEPS_EMR,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "\n",
    "watch_step = EmrStepSensor(\n",
    "    task_id='watch_step',\n",
    "    job_flow_id=\"{{ task_instance.xcom_pull(task_ids='create_emr', key='return_value') }}\",\n",
    "    step_id=\"{{ task_instance.xcom_pull('add_step', key='return_value')[0] }}\",\n",
    "    aws_conn_id='aws_default',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "terminate_emr = EmrTerminateJobFlowOperator(\n",
    "    task_id='terminate_emr',\n",
    "    job_flow_id=\"{{ task_instance.xcom_pull('create_emr', key='return_value') }}\",\n",
    "    aws_conn_id='aws_default',\n",
    "    trigger_rule=TriggerRule.ALL_DONE,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "create_emr >> add_step >> watch_step >> terminate_emr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_suite_ge(spark, input_path, output_path):\n",
    "    path_data = join(input_path, 'sales', 'amazon.csv')\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(path_data)\n",
    "    df_ge = SparkDFDataset(df)\n",
    "\n",
    "    context = create_context_ge(output_path)\n",
    "\n",
    "    suite: ExpectationSuite = context.get_expectation_suite(\n",
    "        expectation_suite_name=suite_name)\n",
    "\n",
    "    add_profile_suite(context, df_ge)\n",
    "\n",
    "    df_validator = create_validator(context, suite, df)\n",
    "    df_validator = add_tests_suite(df_validator)\n",
    "\n",
    "    results = df_validator.validate(expectation_suite=suite)\n",
    "    context.build_data_docs(site_names=[\"s3_site\"])\n",
    "\n",
    "    if results['success']:\n",
    "        print(f\"A suite de testes foi executada com sucesso: {str(results['success'])}\")\n",
    "        print(\"Ação de validação caso seja necessário\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_suite_ge(spark, 's3://bucket-boto-gabrafur-usp/fixed/banco/', 's3://bucket-boto-gabrafur-usp/fixed/banco_analisys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_suite_ge(spark, 's3://bucket-boto-gabrafur-usp/fixed/empregados/', 's3://bucket-boto-gabrafur-usp/fixed/empregados_analisys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_suite_ge(spark, 's3://bucket-boto-gabrafur-usp/fixed/reclamacoes/', 's3://bucket-boto-gabrafur-usp/fixed/reclamacoes_analisys/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
