{
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "Welcome to the Glue Interactive Sessions Kernel\n\nFor more information on available magic commands, please type %help in any new cell.\n\n\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n\nInstalled kernel version: 0.38.1 \n\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::805766217211:role/LabRole\n\nTrying to create a Glue session for the kernel.\n\nWorker Type: G.1X\n\nNumber of Workers: 5\n\nSession ID: c67cd576-3818-4a8e-82af-9404e3081bdd\n\nJob Type: glueetl\n\nApplying the following default arguments:\n\n--glue_kernel_version 0.38.1\n\n--enable-glue-datacatalog true\n\nWaiting for session c67cd576-3818-4a8e-82af-9404e3081bdd to get into ready status...\n\nSession c67cd576-3818-4a8e-82af-9404e3081bdd has been created.\n\n\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import os\n\nclass DataWriter:\n    def write_parquet(self, df, output_directory, mode=\"overwrite\", repartition=True):\n        if repartition:\n            df.repartition(1).write.mode(mode).parquet(output_directory)\n        else:\n            df.write.mode(mode).parquet(output_directory)\n            \n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import DataFrame\n\nclass UnsupportedFileType(Exception):\n    def __init__(self, file_type):\n        self.file_type = file_type\n        self.message = f\"File(s) of type {file_type} not supported\"\n        super().__init__(self.message)\n\nclass ExtractData:\n    def __init__(self, spark, file_directory: list, file_type: str, separator: str = ';', header: bool = True, encoding='utf-8'):\n        self.file_directory = file_directory\n        self.file_type = file_type\n        self.separator = separator\n        self.spark = spark\n        self.header = header\n        self.encoding = encoding\n\n    def extract(self) -> DataFrame:\n        if self.file_type in ('csv', 'tsv'):\n            return \\\n                self.spark.read.options(\n                    delimiter=self.separator,\n                    header=self.header,\n                    encoding=self.encoding\n                ).csv(self.file_directory)\n        elif self.file_type == 'parquet':\n            return self.spark.read.parquet(self.file_directory)\n        else:\n            raise UnsupportedFileType(self.file_type)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "json_column_rename = {\n    \"BanksTransformation\": {\n        \"Segmento\" : \"segmento\",\n        \"CNPJ\": \"cnpj\",\n        \"Nome\": \"nome\"\n    },\n    \"EmployeesTransformation\": {\n        \"employer-website\" : \"employer_website\",\n        \"employer-headquarters\": \"employer_headquarters\",\n        \"employer-founded\": \"employer_founded\",\n        \"employer-industry\": \"employer_industry\",\n        \"employer-revenue\": \"employer_revenue\",\n        \"Geral\": \"geral\",\n        \"Cultura e valores\": \"cultura_valores\",\n        \"Diversidade e inclusão\": \"diversidade_inclusao\",\n        \"Qualidade de vida\": \"qualidade_vida\",\n        \"Alta liderança\": \"alta_lideranca\",\n        \"Remuneração e benefícios\": \"remuneracao_beneficios\",\n        \"Oportunidades de carreira\": \"oportunidades_carreira\",\n        \"Recomendam para outras pessoas(%)\": \"percentual_recomendam_para_outras_pessoas\",\n        \"Perspectiva positiva da empresa(%)\": \"percentual_perspectiva_positiva_empresa\",\n        \"CNPJ\": \"cnpj\",\n        \"Nome\": \"nome\",\n        \"Segmento\": \"segmento\"\n    },\n    \"ComplaintsTransformation\": {\n        \"Ano\" : \"ano\",\n        \"Trimestre\": \"trimestre\",\n        \"Categoria\": \"categoria\",\n        \"Tipo\": \"tipo\",\n        \"CNPJ IF\": \"cnpj_if\",\n        \"Instituição financeira\": \"instituicao_financeira\",\n        \"Índice\": \"indice\",\n        \"Quantidade de reclamações reguladas procedentes\": \"qtd_reclamacoes_reguladas_procedentes\",\n        \"Quantidade de reclamações reguladas - outras\": \"qtd_reclamacoes_reguladas_outras\",\n        \"Quantidade de reclamações não reguladas\": \"qtd_reclamacoes_nao_reguladas\",\n        \"Quantidade total de reclamações\": \"qtd_total_reclamacoes\",\n        \"Quantidade total de clientes - CCS e SCR\": \"qtd_total_clientes_ccs_scr\",\n        \"Quantidade de clientes - CCS\": \"qtd_clientes_ccs\",\n        \"Quantidade de clientes - SCR\": \"qtd_clientes_scr\"\n    }\n}",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from abc import ABC, abstractmethod\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql import DataFrame\nimport os\n\n\nclass TransformData(ABC):\n    \"\"\"\n    Gathers general functions for all transformations.\n    \"\"\"\n    def format_cnpj(self, value):\n        return F.when((value == ' ') | (value == ''), value).otherwise(F.lpad(value, 8, '0'))\n\n\n    def load_column_rename_mappings(self, transformation_name):\n#         json_file_path = os.path.join(os.path.dirname(__file__), 'column_rename.json')\n        column_rename_mappings = json_column_rename\n        return column_rename_mappings.get(transformation_name, {})\n\n\n    def rename_columns(self, df: DataFrame, column_rename) -> DataFrame:\n        for old_name, new_name in column_rename.items():\n            df = df.withColumnRenamed(old_name, new_name)\n        return df\n\n\n    @abstractmethod\n    def transform(self) -> DataFrame:\n        pass\n\n\nclass BanksTransformation(TransformData):\n    \"\"\"\n    Functions for transforming the pandas dataframe for banks.\n    \"\"\"\n    def __init__(self, df: DataFrame):\n        \"\"\"\n        Receives the dataframe.\n        \"\"\"\n        self.df = df\n        self.column_rename = self.load_column_rename_mappings('BanksTransformation')\n\n\n\n    def transform(self) -> DataFrame:\n        \"\"\"\n        Function to rename (to snake_case), format, and adjust data in the 'Segment', 'CNPJ', and 'Name' columns.\n        Returns a dataframe.\n        \"\"\"\n        transformed_df = self.rename_columns(self.df, self.column_rename)\n        transformed_df = transformed_df.withColumn(\"cnpj\", self.format_cnpj(F.col(\"cnpj\")))\n        transformed_df = transformed_df.withColumn(\"nome\", F.regexp_replace(F.col(\"nome\").cast(StringType()), ' - PRUDENCIAL', ''))\n        return transformed_df\n\n\nclass EmployeesTransformation(TransformData):\n    \"\"\"\n    Functions for transforming the pandas dataframe for employees.\n    \"\"\"\n    def __init__(self, df: DataFrame):\n        \"\"\"\n        Receives the dataframe.\n        \"\"\"\n        self.df = df\n        self.column_rename = self.load_column_rename_mappings('EmployeesTransformation')\n\n\n    def transform(self) -> DataFrame:\n        \"\"\"\n        Function to rename (to snake_case), format, and change data types.\n        Returns a dataframe.\n        \"\"\"\n        transformed_df = self.rename_columns(self.df, self.column_rename)\n\n        transformed_df = transformed_df\\\n            .withColumn(\"employer_name\", F.col('employer_name').cast(StringType()))\\\n            .withColumn(\"reviews_count\", F.col('reviews_count').cast(IntegerType()))\\\n            .withColumn(\"culture_count\", F.col('culture_count').cast(IntegerType()))\\\n            .withColumn(\"salaries_count\", F.col('salaries_count').cast(IntegerType()))\\\n            .withColumn(\"benefits_count\", F.col('benefits_count').cast(IntegerType()))\\\n            .withColumn(\"employer_website\", F.col('employer_website').cast(StringType()))\\\n            .withColumn(\"employer_headquarters\", F.col('employer_headquarters').cast(StringType()))\\\n            .withColumn(\"employer_founded\", F.col('employer_founded').cast(IntegerType()))\\\n            .withColumn(\"employer_industry\", F.col('employer_industry').cast(StringType()))\\\n            .withColumn(\"employer_revenue\", F.col('employer_revenue').cast(StringType()))\\\n            .withColumn(\"url\", F.col('url').cast(StringType()))\\\n            .withColumn(\"geral\", F.col('geral').cast(DecimalType(20,2)))\\\n            .withColumn(\"cultura_valores\", F.col('cultura_valores').cast(DecimalType(20,2)))\\\n            .withColumn(\"diversidade_inclusao\", F.col('diversidade_inclusao').cast(DecimalType(20,2)))\\\n            .withColumn(\"qualidade_vida\", F.col('qualidade_vida').cast(DecimalType(20,2)))\\\n            .withColumn(\"alta_lideranca\", F.col('alta_lideranca').cast(DecimalType(20,2)))\\\n            .withColumn(\"remuneracao_beneficios\", F.col('remuneracao_beneficios').cast(DecimalType(20,2)))\\\n            .withColumn(\"oportunidades_carreira\", F.col('oportunidades_carreira').cast(DecimalType(20,2)))\\\n            .withColumn(\"percentual_recomendam_para_outras_pessoas\", F.col('percentual_recomendam_para_outras_pessoas').cast(DecimalType(20,2)))\\\n            .withColumn(\"percentual_perspectiva_positiva_empresa\", F.col('percentual_perspectiva_positiva_empresa').cast(DecimalType(20,2)))\\\n            .withColumn(\"nome\", F.col('nome').cast(StringType()))\\\n            .withColumn(\"segmento\", F.col('segmento').cast(StringType()))\\\n            .withColumn(\"match_percent\", F.col('match_percent').cast(FloatType()))\n        #             .withColumn('cnpj', self.format_cnpj(F.col(\"cnpj\")))\\\n\n\n        return transformed_df\n\n\n    def calculate_aggregates(self, df) -> DataFrame:\n        \"\"\"\n        Function to return a pandas dataframe of a pivot table grouped by the 'name' column,\n        aggregating the 'geral' and 'remuneracao_beneficios' columns by mean.\n        \"\"\"\n        aggregated_df  = df.groupby('nome').agg(\n            F.round(F.mean('geral'), 2).alias('geral'),\n            F.round(F.mean('remuneracao_beneficios'), 2).alias('remuneracao_beneficios')\n        )\n        return aggregated_df \n\n\nclass ComplaintsTransformation(TransformData):\n    \"\"\"\n    Functions for transforming the pandas dataframe for complaints.\n    \"\"\"\n    def __init__(self, df: DataFrame):\n        \"\"\"\n        Receives the dataframe.\n        \"\"\"\n        self.df = df\n        self.column_rename = self.load_column_rename_mappings('ComplaintsTransformation')\n\n\n    def transform(self) -> DataFrame:\n        \"\"\"\n        Function to rename (to snake_case), format, and change data types.\n        Returns a dataframe.\n        \"\"\"\n        transformed_df = self.rename_columns(self.df, self.column_rename)\n\n        transformed_df = transformed_df\\\n            .withColumn(\"ano\", F.col('ano').cast(IntegerType()))\\\n            .withColumn('trimestre', F.col(\"trimestre\").cast(StringType()))\\\n            .withColumn('categoria', F.col(\"categoria\").cast(StringType()))\\\n            .withColumn('tipo', F.col(\"tipo\").cast(StringType()))\\\n            .withColumn(\"cnpj\", self.format_cnpj(F.col(\"cnpj_if\")))\\\n            .withColumn(\"nome\", F.regexp_replace(F.col(\"instituicao_financeira\").cast(StringType()), ' \\(conglomerado\\)', ''))\\\n            .withColumn(\"indice\", F.regexp_replace(F.col('indice').cast(StringType()), ',', '.').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_reclamacoes_reguladas_procedentes\", F.col('qtd_reclamacoes_reguladas_procedentes').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_reclamacoes_reguladas_outras\", F.col('qtd_reclamacoes_reguladas_outras').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_reclamacoes_nao_reguladas\", F.col('qtd_reclamacoes_nao_reguladas').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_total_reclamacoes\", F.col('qtd_total_reclamacoes').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_total_clientes_ccs_scr\", F.col('qtd_total_clientes_ccs_scr').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_clientes_ccs\", F.col('qtd_clientes_ccs').cast(DecimalType(20,2)))\\\n            .withColumn(\"qtd_clientes_scr\", F.col('qtd_clientes_scr').cast(DecimalType(20,2)))\n\n        return transformed_df\n\n\n    def calculate_aggregates(self, df) -> DataFrame:\n        \"\"\"\n        Function to return a pandas dataframe of a pivot table grouped by the 'name' column,\n        aggregating columns like 'indice', 'qtd_total_reclamacoes', and 'qtd_total_clientes_ccs_scr' by mean.\n        \"\"\"\n        aggregated_df  = df.groupby('nome').agg(\n            F.round(F.mean('indice'), 2).alias(\"indice\"),\n            F.round(F.mean('qtd_total_reclamacoes'), 2).alias(\"qtd_total_reclamacoes\"),\n            F.max('qtd_total_clientes_ccs_scr').alias(\"qtd_total_clientes_ccs_scr\")\n        )\n        return aggregated_df",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "extract_banks = ExtractData(\n    spark,\n    file_directory='s3://857119631738-atividade05-trusted/Bancos', \n    file_type='parquet'\n)\ndf_banks = extract_banks.extract()\n\nextract_employees = ExtractData(\n    spark,\n    file_directory='s3://857119631738-atividade05-trusted/Empregados', \n    file_type='parquet'\n)\ndf_trusted_employees = extract_employees.extract()\n\nextract_complaints = ExtractData(\n    spark,\n    file_directory='s3://857119631738-atividade05-trusted/Reclamacoes', \n    file_type='parquet'\n)\ndf_trusted_complaints = extract_complaints.extract()\n\ntransform_employees = EmployeesTransformation(df_trusted_employees)\ndf_grouped_employees = transform_employees.calculate_aggregates(df_trusted_employees)\n\ntransform_complaints = ComplaintsTransformation(df_trusted_complaints)\ndf_grouped_complaints = transform_complaints.calculate_aggregates(df_trusted_complaints)\n\ndf_complaints_banks = df_banks.join(df_grouped_complaints, on=['nome'], how='inner')\ndf_complaints_banks_employees = df_complaints_banks.join(df_grouped_employees, on=['nome'], how='inner')\n\noutput_directory = 's3://857119631738-atividade05-delivery/atividade05'\nwrite_data = DataWriter()\nwrite_data.write_parquet(df_complaints_banks_employees, output_directory)\n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": "\n"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": null,
			"outputs": []
		}
	]
}